{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "780cf295-7141-43e8-b8b8-199b14071e2a",
   "metadata": {},
   "source": [
    "# Coding your own RNN\n",
    "\n",
    "Using this pre-filled notebook, we will code our own RNN for sentence classification. For now, we'll keep using IMDB, as the goal of this part is to understand how an RNN works.\n",
    "\n",
    "Unlike our previous lab, we will also learn the embedding layer. Which means we need to deal with vocabulary by ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26c411e-1cd5-4a1c-9b3d-de16e26db901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Callable, Dict, Generator, List, Tuple\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.vocab import vocab, Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec040734-ff61-4c85-982c-acb2a5bd6d8c",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We load the dataset and split the training set in a stratified train/validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b598f9-36b5-43e3-bb25-488b0fb53aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/ethan/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8beeeee724da470e824f16d237bddf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/ethan/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-5f37fd0866e4f89f.arrow and /home/ethan/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-dd5732a0e6ac784c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20000, 2), (5000, 2), (25000, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "train_dataset = dataset[\"train\"].train_test_split(\n",
    "    stratify_by_column=\"label\", test_size=0.2, seed=42\n",
    ")\n",
    "test_df = dataset[\"test\"]\n",
    "train_df = train_dataset[\"train\"]\n",
    "valid_df = train_dataset[\"test\"]\n",
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f309e444-d52d-4f87-8d18-7bb470b7cfcd",
   "metadata": {},
   "source": [
    "## Vocabulary (1 point)\n",
    "\n",
    "**\\[1 point\\]** Build your own vocabulary. The [example provided in torchtext documentation](https://pytorch.org/text/stable/vocab.html#id1) might be of help.\n",
    "* Don't forge to setup the `min_freq` parameter to not include unfrequent noise.\n",
    "* You will need a tokenizer. Reuse the `basic_english` one from the our previous lab.\n",
    "* For an RNN we need two special tokens: `<unk>`, for unknown words, and `<pad>` for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59cb42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(base_text):\n",
    "    \"\"\"\n",
    "    Preprocess the text before classification\n",
    "    Args:\n",
    "        base_text: the string to preprocess\n",
    "    Return:\n",
    "        The preprocessed text\n",
    "    \"\"\"\n",
    "    return base_text.replace(\"<br />\",' ')\n",
    "\n",
    "def create_vocab(texts, frequencies = {}):\n",
    "    for text in texts:\n",
    "        for word in preprocess(text).split(\" \"):\n",
    "            if word not in frequencies:\n",
    "                frequencies[word] = 1\n",
    "                continue\n",
    "            frequencies[word] += 1\n",
    "    return dict(sorted(frequencies.items(), key=lambda x: x[1], reverse=True))\n",
    "frequencies = create_vocab(train_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d708453",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n",
    "vocabulary = vocab(frequencies, min_freq = 100, specials=[\"<unk>\", \"<pad>\"])\n",
    "vocabulary.set_default_index(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89386d66-f758-4d87-b786-9d570eb22f2f",
   "metadata": {},
   "source": [
    "## Vectorize and batch the input (3 points)\n",
    "\n",
    "As seen in class, our model should take one-hot encoded vectors corresponding to the each token vocabulary id. However, computing a vector x matrix multiplication for every input is unnecessarily costly. Multiplying a one-hot vector with a matrix is the equivalent of taking one row of the matrix. In pyTorch, we provide ids for each token which will be used as input to an `nn.Embedding` layer. The id is simply the row in the embedding matrix.\n",
    "\n",
    "**\\[1 point\\]** Fill the `vectorize_text` function returning a 1D torch tensor of `torch.long` for each input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6fc4eb-2f25-43ee-8b2f-a9154545ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(\n",
    "    text: str, vocabulary: Vocab, tokenizer: Callable[[str], List[str]]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate a tensor of vocabluary IDs for a given text.\n",
    "    Args:\n",
    "        text: the input text.\n",
    "        vocabulary: a Vocab objects.\n",
    "        tokenizer: a text tokenizer.\n",
    "    Returns:\n",
    "        A tensor of IDs (torch.long).\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(preprocess(text))\n",
    "    tokens_ids = vocabulary.lookup_indices(tokens)\n",
    "    return torch.tensor(tokens_ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4a9058-ad04-43b9-bf5c-680afb44e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = partial(vectorize_text, vocabulary=vocabulary, tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9717208d-2f50-4d16-b170-904beeeb71ad",
   "metadata": {},
   "source": [
    "Check the function is working correctly, especially it should return the right special id for unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9727204a-ecff-4e4d-a316-543865d52a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 47,   0, 143, 229, 556,  42, 425, 425, 425,   0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"Some text I am thinking about... ragafqfa\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69a2018e",
   "metadata": {},
   "source": [
    "Result:\n",
    "* tensor([ 47,   0, 143, 229, 556,  42, 425, 425, 425,   0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97eb948c-cfae-47b1-b8ce-bafa358afe65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03742980b87a4e1e96a9bd43ac7cfbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87868ebe3d234ffca5c4459b0c96ae67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1559cf6b41414caf88c1d3b8b0657666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = [text_pipeline(text) for text in tqdm(train_df[\"text\"])]\n",
    "y_train = train_df[\"label\"]\n",
    "X_valid = [text_pipeline(text) for text in tqdm(valid_df[\"text\"])]\n",
    "y_valid = valid_df[\"label\"]\n",
    "X_test = [text_pipeline(text) for text in tqdm(test_df[\"text\"])]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67138763-f848-4dd7-9036-68df352d22a0",
   "metadata": {},
   "source": [
    "To speed up the training process, we turn the inputs into batches, as we did last time. For batches to work, every line must have the same lengths. Last time, it was implicit as only a vector (the average of all embeddings) was provided. This time, every line has the length of a different review.\n",
    "\n",
    "To go around this problem, we use padding. So every line within a batch is padded to the length of its longest element.\n",
    "\n",
    "* **\\[1 point\\]** Fill the data generator function.\n",
    "* **\\[1 point\\]** On which side should you pad and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88dd162-8107-4f05-bc8a-2fd313a3b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(\n",
    "    X: List[torch.tensor], y: List[int], pad_id: int, batch_size: int = 32\n",
    ") -> Generator[Tuple[torch.Tensor, torch.Tensor], None, None]:\n",
    "    \"\"\"\n",
    "    Yield batches from given input data and labels.\n",
    "    Args:\n",
    "        X: a list of tensor (input features).\n",
    "        y: the corresponding labels.\n",
    "        batch_size: the size of every batch [32].\n",
    "    Returns:\n",
    "        A tuple of tensors (features, labels).\n",
    "    \"\"\"\n",
    "    X, y = shuffle(X, y)\n",
    "    n_batches = len(X) // batch_size\n",
    "    for i in range(n_batches):\n",
    "        batch_X = X[i * batch_size : (i + 1) * batch_size]\n",
    "        batch_y = y[i * batch_size : (i + 1) * batch_size]\n",
    "        batch_X = nn.utils.rnn.pad_sequence(batch_X, padding_value=pad_id)\n",
    "        yield batch_X, torch.tensor(batch_y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e10342-4d6b-45c4-8e05-68ef6375b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token = \"<pad>\"\n",
    "train_gen = lambda: data_generator(X_train, y_train, vocabulary[pad_token])\n",
    "valid_gen = lambda: data_generator(X_valid, y_valid, vocabulary[pad_token])\n",
    "test_gen = lambda: data_generator(X_test, y_test, vocabulary[pad_token])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4489d625-f1ad-49ea-8b54-74463e04877f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classifier (3 points)\n",
    "\n",
    "**\\[3 points\\]** Code your own RNN. Fill the `RNN` class correctly. Remember an RNN has 3 matrices and an embedding layer (see course slide 61).\n",
    "* The embedding layer turns a one-hot vectors into dense vectors.\n",
    "* The first matrix (W) connects the embedding to the hidden layer.\n",
    "  * `embedding_size -> hidden_size`\n",
    "* The second matrix (U) connect the previous hidden layer to the current one.\n",
    "  * `hidden_size -> hidden_size`\n",
    "* These to vectors are added and go through an activation function (e.g. $h_t = tanh(Wx_i+Uh_{t-1})$).\n",
    "* The last matrix (V) connects the hidden layer to the hidden layer to the output.\n",
    "  * `hidden_size -> 1`\n",
    "* Donc forget to add an `init_hidden` function which initialize the first hidden layer to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "460135c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \"\"\"A simple RNN module with word embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, embed_size: int, hidden_size, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: vocabulary size.\n",
    "            embed_size: embedding dimensions.\n",
    "            hidden_size: hidden layer size.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        # The word embedding layer.\n",
    "        self.embed = nn.Embedding(self.vocab_size, self.embed_size, device = self.device)\n",
    "        self.U = nn.Linear(self.hidden_size, self.hidden_size, device=self.device)\n",
    "        self.V = nn.Linear(self.hidden_size, 1, device=self.device)\n",
    "        self.W = nn.Linear(self.embed_size, self.hidden_size, device=self.device)\n",
    "\n",
    "    def parameters(self) -> Iterator[Parameter]:\n",
    "        yield self.W.weight\n",
    "        yield self.U.weight\n",
    "        yield self.V.weight\n",
    "\n",
    "    def h(self, t, X):\n",
    "        if t == 0:\n",
    "            return torch.zeros(self.hidden_size, X.size(2)).to(self.device)\n",
    "        Uh = self.U(self.h(t-1, X).transpose(0, 1))\n",
    "        Uh = Uh.expand(X.size(0), Uh.size(0), Uh.size(1))\n",
    "        Wx = self.W(X)\n",
    "        return torch.tanh(Uh + Wx).to(self.device)\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "\n",
    "        embed_X = self.embed(X)\n",
    "        h = self.h(1, embed_X)\n",
    "        y = self.V(h.transpose(0, 1))\n",
    "        return y.reshape(y.size(0), y.size(1))      \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c665df6-ff9a-4b66-80fe-8abe62d895c9",
   "metadata": {},
   "source": [
    "## Training (2 points)\n",
    "\n",
    "Training is a bit different than usual. We will need to sequentially (but in \"batch parallel\") go through an input, keeping track of the hidden layer, and use the last output as prediction.\n",
    "\n",
    "**\\[2 point\\]** Code the training loop.\n",
    "* Note that for each batch, you need to loop through the whole input and use the output of the last token as input to your criterion.\n",
    "* Keep the best model evaluated on the validation set.\n",
    "* Plot the training and validation losses.\n",
    "* Training will take some time (~30 min on a T4 GPU). Make sure your results appear in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9053b8-19f3-45b4-a434-2f8cef8a1f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "937cd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    criterion: Callable,\n",
    "    optimizier: torch.optim.Optimizer,\n",
    "    n_epochs: int,\n",
    "    train_gen: Callable,\n",
    "    valid_gen: Callable,\n",
    "):\n",
    "    best_model = model\n",
    "    best_loss = np.inf\n",
    "    i=0\n",
    "    for _ in tqdm(range(n_epochs), desc=\"Epochs\"):\n",
    "\n",
    "        for X, y in train_gen():\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizier.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            y = y.reshape(y.size(0), 1).expand(y.size(0), y_pred.size(1))\n",
    "            loss = criterion(y_pred, y.float())\n",
    "            loss.backward()\n",
    "            optimizier.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print(f\"Training loss: {loss.item()}\")\n",
    "            \n",
    "        for X, y in valid_gen():\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(X)\n",
    "                y = y.reshape(y.size(0), 1).expand(y.size(0), y_pred.size(1))\n",
    "                loss = criterion(y_pred, y.float())\n",
    "                if loss.item() < best_loss:\n",
    "                    best_loss = loss.item()\n",
    "                    best_model = model\n",
    "                    \n",
    "        if i % 20 == 0:\n",
    "            print(f\"Best Validation loss: {best_loss}\")\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46cdc558-249b-4c26-b1e5-fc1c0a78d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding = 32\n",
    "n_hidden = 64\n",
    "model = RNN(len(vocabulary.get_itos()), n_embedding, n_hidden, device).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "355b8423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cd8e3f3151499ba9192a5bddbbebfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6944425702095032\n",
      "Best Validation loss: 0.6890242695808411\n",
      "Training loss: 0.6899073123931885\n",
      "Best Validation loss: 0.6747045516967773\n",
      "Training loss: 0.6898512840270996\n",
      "Best Validation loss: 0.6747045516967773\n",
      "Training loss: 0.6929174661636353\n",
      "Best Validation loss: 0.6747045516967773\n",
      "Training loss: 0.7056082487106323\n",
      "Best Validation loss: 0.6720477938652039\n",
      "Training loss: 0.6918027400970459\n",
      "Best Validation loss: 0.6655289530754089\n",
      "Training loss: 0.6927348375320435\n",
      "Best Validation loss: 0.6655289530754089\n",
      "Training loss: 0.6908631324768066\n",
      "Best Validation loss: 0.6655289530754089\n",
      "Training loss: 0.6956551671028137\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6875395178794861\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6935694813728333\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.698187530040741\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.693101167678833\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6905004382133484\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6879173517227173\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6921180486679077\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6891822814941406\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6918699145317078\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6906906366348267\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6972622871398926\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6892645359039307\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6907958984375\n",
      "Best Validation loss: 0.6492127180099487\n",
      "Training loss: 0.6887673735618591\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6887199878692627\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6935374140739441\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6939828395843506\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6858437061309814\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6854701042175293\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6905762553215027\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6932013630867004\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6982448101043701\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6882638335227966\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6891294717788696\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6892381906509399\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6924259662628174\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6952608823776245\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6902666687965393\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6912439465522766\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6923109292984009\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6895468831062317\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6935583353042603\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6937001347541809\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6909939646720886\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6935122609138489\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.69642174243927\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6916099786758423\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6918113827705383\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6921186447143555\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6938718557357788\n",
      "Best Validation loss: 0.642731785774231\n",
      "Training loss: 0.6944473385810852\n",
      "Best Validation loss: 0.642731785774231\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model = train(model, criterion, optimizer, 1000, train_gen, valid_gen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04132d42",
   "metadata": {},
   "source": [
    "Last result:\n",
    "* Training loss: 0.6944473385810852\n",
    "* Best Validation loss: 0.642731785774231"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "137dc500-ece2-4efa-8207-758a5f428c26",
   "metadata": {},
   "source": [
    "## Evaluation (1 point)\n",
    "\n",
    "* **\\[1 point\\]** Compute the accuracy for all 3 splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36b10a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accurracy(X, y):\n",
    "    X = nn.utils.rnn.pad_sequence(X, padding_value=vocabulary[pad_token])\n",
    "    X = X.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = best_model(X)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "        y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "        return (y_pred == y).sum().item() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4544dfd-7567-4bea-b484-490b6a7b74e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.56 GiB (GPU 0; 5.79 GiB total capacity; 857.74 MiB already allocated; 4.20 GiB free; 944.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy_train \u001b[39m=\u001b[39m compute_accurracy(X_train, y_train)\n\u001b[1;32m      2\u001b[0m accuracy_valid \u001b[39m=\u001b[39m compute_accurracy(X_valid, y_valid)\n\u001b[1;32m      3\u001b[0m accuracy_test \u001b[39m=\u001b[39m compute_accurracy(X_test, y_test)\n",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m, in \u001b[0;36mcompute_accurracy\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     y_pred \u001b[39m=\u001b[39m best_model(X)\n\u001b[1;32m      6\u001b[0m     y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      7\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(y_pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 45\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X: torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m---> 45\u001b[0m     embed_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed(X)\n\u001b[1;32m     46\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh(\u001b[39m1\u001b[39m, embed_X)\n\u001b[1;32m     47\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV(h\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.56 GiB (GPU 0; 5.79 GiB total capacity; 857.74 MiB already allocated; 4.20 GiB free; 944.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "accuracy_train = compute_accurracy(X_train, y_train)\n",
    "accuracy_valid = compute_accurracy(X_valid, y_valid)\n",
    "accuracy_test = compute_accurracy(X_test, y_test)\n",
    "print(f\"Training accuracy: {accuracy_train}\")\n",
    "print(f\"Validation accuracy: {accuracy_valid}\")\n",
    "print(f\"Test accuracy: {accuracy_test}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c619f3e5",
   "metadata": {},
   "source": [
    "Results:\n",
    "* Could not compute accuracy because of Error CUDA out of memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
